[1m[34mswanlab[0m[0m: swanlab version 0.5.3 is available!  Upgrade: `pip install -U swanlab`    
[1m[34mswanlab[0m[0m: Tracking run with swanlab version 0.4.12                                  
[1m[34mswanlab[0m[0m: Run data will be saved locally in [35m[1m/fs-computility/llmit_d/shared/baitianyi/rl4llm/trl4llm/scripts/swanlog/run-20250325_030455-0e8cd89d[0m[0m
[1m[34mswanlab[0m[0m: ğŸ‘‹ Hi [1m[39mHarrison[0m[0m, welcome to swanlab!
[1m[34mswanlab[0m[0m: Syncing run [33mPPO-gsm8k[0m to the cloud
[1m[34mswanlab[0m[0m: ğŸŒŸ Run `[1mswanlab watch /fs-computility/llmit_d/shared/baitianyi/rl4llm/trl4llm/scripts/swanlog[0m` to view SwanLab Experiment Dashboard locally
[1m[34mswanlab[0m[0m: ğŸ  View project at [34m[4mhttps://swanlab.cn/@Harrison/trl4llm[0m[0m
[1m[34mswanlab[0m[0m: ğŸš€ View run at [34m[4mhttps://swanlab.cn/@Harrison/trl4llm/runs/iqwdpnaoydia2rq36ewii[0m[0m
  0%|                                                                                                                          | 0/5605 [00:00<?, ?it/s]  File "/fs-computility/llmit_d/shared/baitianyi/miniconda3/envs/trl/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[1m[34mswanlab[0m[0m: Error happened while training
[1m[34mswanlab[0m[0m: ğŸŒŸ Run `[1mswanlab watch /fs-computility/llmit_d/shared/baitianyi/rl4llm/trl4llm/scripts/swanlog[0m` to view SwanLab Experiment Dashboard locally
[1m[34mswanlab[0m[0m: ğŸ  View project at [34m[4mhttps://swanlab.cn/@Harrison/trl4llm[0m[0m
[1m[34mswanlab[0m[0m: ğŸš€ View run at [34m[4mhttps://swanlab.cn/@Harrison/trl4llm/runs/iqwdpnaoydia2rq36ewii[0m[0m
                                                                                                    
    return _run_code(code, main_globals, None,
  File "/fs-computility/llmit_d/shared/baitianyi/miniconda3/envs/trl/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/fs-computility/llmit_d/shared/baitianyi/rl4llm/trl4llm/trl4llm/trainer/ppo.py", line 99, in <module>
    train(config_name=args.config)
  File "/fs-computility/llmit_d/shared/baitianyi/rl4llm/trl4llm/trl4llm/trainer/ppo.py", line 79, in train
    trainer.train()
  File "/fs-computility/llmit_d/shared/baitianyi/miniconda3/envs/trl/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py", line 405, in train
    data = next(iter_dataloader)
  File "/fs-computility/llmit_d/shared/baitianyi/miniconda3/envs/trl/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py", line 352, in repeat_generator
    yield from dataloader
  File "/fs-computility/llmit_d/shared/baitianyi/miniconda3/envs/trl/lib/python3.10/site-packages/accelerate/data_loader.py", line 566, in __iter__
    current_batch = next(dataloader_iter)
  File "/fs-computility/llmit_d/shared/baitianyi/miniconda3/envs/trl/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/fs-computility/llmit_d/shared/baitianyi/miniconda3/envs/trl/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/fs-computility/llmit_d/shared/baitianyi/miniconda3/envs/trl/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/fs-computility/llmit_d/shared/baitianyi/miniconda3/envs/trl/lib/python3.10/site-packages/transformers/data/data_collator.py", line 271, in __call__
    batch = pad_without_fast_tokenizer_warning(
  File "/fs-computility/llmit_d/shared/baitianyi/miniconda3/envs/trl/lib/python3.10/site-packages/transformers/data/data_collator.py", line 66, in pad_without_fast_tokenizer_warning
    padded = tokenizer.pad(*pad_args, **pad_kwargs)
  File "/fs-computility/llmit_d/shared/baitianyi/miniconda3/envs/trl/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 3314, in pad
    raise ValueError(
You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['answer', 'prompt']
